{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqOt6Sv7AsMi"
   },
   "outputs": [],
   "source": [
    "# # Required installations (run once)\n",
    "# !brew install wget  # Added by Miles\n",
    "# !pip install --upgrade --ignore-installed wrapt  # Added by Miles\n",
    "# !pip install tensorflow==2.0.0-beta0  # Edited by Miles (switch to CPU version)\n",
    "# !pip install tensorflow_datasets  # Added by Miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBMcobPHdD8O"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import pymongo        # MongoDB\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import helper\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from io import BytesIO\n",
    "import boto3\n",
    "\n",
    "from image_feature_extractor import ImageFeatureExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mongo Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to secret\n",
    "#secret_path = os.path.join(os.environ['HOME'], '.secret', 'mongo.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = helper.get_keys(secret_path)\n",
    "# mongo_user = keys['user_id']\n",
    "# mongo_pw = keys['password']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0GoKGm1duzgk"
   },
   "source": [
    "## Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince',\n",
       " 'vince']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from os import walk\n",
    "\n",
    "image_paths = []\n",
    "target_labels = []\n",
    "for dirpath, dirnames, filenames in os.walk('downloads/all_photos'):\n",
    "#for dirpath, dirnames, filenames in os.walk('test_data'):\n",
    "    for ff in filenames:\n",
    "        if ff[:1] != '.':\n",
    "            curr_path = os.path.join('.',dirpath, ff)\n",
    "            temp_name = dirpath[dirpath.rfind('/') + 1:]\n",
    "#             print(curr_path)  \n",
    "            target_labels.append(temp_name)\n",
    "            image_paths.append(curr_path)\n",
    "        \n",
    "target_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./downloads/all_photos/vince/110.matt-schulzeactorwestwood-los-angeles-usa05082002lab7078-DKX8MR.jpg',\n",
       " './downloads/all_photos/vince/84.Matt+Schulze+outside+ArcLight+Theatre+Lp9hn7BIIGqs.jpg',\n",
       " './downloads/all_photos/vince/67.the-transporter-film-premiere-los-angeles-america-shutterstock-editorial-391154x.jpg',\n",
       " './downloads/all_photos/vince/28.mattschulze-torque-5.jpg',\n",
       " './downloads/all_photos/vince/179.Matt-in-Blade-II-matt-schulze-26020173-853-480.jpg',\n",
       " './downloads/all_photos/vince/140.matt-schulze-actor-scandal.png',\n",
       " './downloads/all_photos/vince/71.Matt-in-Torque-matt-schulze-23059204-700-525.jpg',\n",
       " './downloads/all_photos/vince/5.7783020.jpg',\n",
       " './downloads/all_photos/vince/51.matt-schulze-kiss-of-the-dragon-film-prem-century-city-los-angeles-H82NWB.jpg',\n",
       " './downloads/all_photos/vince/17.Matt-in-Torque-matt-schulze-23058761-700-525.jpg',\n",
       " './downloads/all_photos/vince/21.depositphotos_17572761-stock-photo-matt-schulze.jpg',\n",
       " './downloads/all_photos/vince/63.Matt-in-The-Transporter-matt-schulze-21145064-853-480.jpg',\n",
       " './downloads/all_photos/vince/164.Matt-in-Blade-II-matt-schulze-26020227-853-480.jpg',\n",
       " './downloads/all_photos/vince/19.index1-265.jpg',\n",
       " './downloads/all_photos/vince/53.Matt-in-The-Fast-and-the-Furious-matt-schulze-21118294-900-506.jpg',\n",
       " './downloads/all_photos/vince/161.600px-T-Bruni8mmM1911Blank02a.jpg',\n",
       " './downloads/all_photos/vince/33.australian-actor-matt-schulze-world-450w-98742659.jpg',\n",
       " './downloads/all_photos/vince/93.600x600.jpg',\n",
       " './downloads/all_photos/vince/142.006%2BMatt%2BSchulze%2Bas%2BVince.jpg',\n",
       " './downloads/all_photos/vince/27.43888-25707.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "19IQ2gqneqmS",
    "outputId": "2659862d-e726-47b0-cdd9-355938312718"
   },
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def extract_features(image):\n",
    "    \"\"\"Return a vector of 1280 deep features for image.\"\"\"\n",
    "    image_resized = prepare_image(image)\n",
    "    image_np = image_resized.numpy()\n",
    "    images_np = np.expand_dims(image_np, axis=0)\n",
    "    image_np.shape, images_np.shape\n",
    "    deep_features = model.predict(images_np)\n",
    "    return deep_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "extract_features(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "extractor = ImageFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('extract_deep_features', extractor),\n",
    "    ('classify', forest)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_paths, target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./downloads/all_photos/megan/36.large533cb2969923d@2x.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/PIL/Image.py:952: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9 bytes but only got 8. Skipping tag 42037\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 6. Skipping tag 18\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('extract_deep_features', ImageFeatureExtractor(height=160,\n",
       "           model=<tensorflow.python.keras.engine.sequential.Sequential object at 0x1a308656a0>,\n",
       "           width=160)), ('classify', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=No..._jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "png = ['./downloads/all_photos/dominic/118.fate-of-the-furious-banner-6.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/PIL/Image.py:952: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['brixton', 'brian', 'brian', ..., 'deckard', 'gisele', 'brian'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/PIL/Image.py:952: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32556270096463025"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import webbrowser\n",
    "\n",
    "# !cd downloads/public_photos\n",
    "# !wget http://www.sosia.biz/files/immagini/1289210942-DSCF0851.JPG\n",
    "# !ls\n",
    "\n",
    "vinny = ['http://www.sosia.biz/files/immagini/1289210942-DSCF0851.JPG']\n",
    "laura = ['https://cdn-images-1.medium.com/max/1200/1*jM7PrjvG20306cXwjgN6hA@2x.jpeg']\n",
    "mia = ['https://media.licdn.com/dms/image/C4E03AQEUu7pgy0zqrw/profile-displayphoto-shrink_200_200/0?e=1563408000&v=beta&t=IQESr0Ho16othgeTRgp0nrGlXRkv6c-WiSHf_nCzRlk']\n",
    "werlindo = ['https://cdn-images-1.medium.com/max/1200/2*T33SKqm3ldv2QkTE3QQ0Dw.jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.sosia.biz/files/immagini/1289210942-DSCF0851.JPG']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vinny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['roman'], dtype='<U7')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(werlindo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE EVERYTHING BELOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import tensorflow as tf\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    def __init__(self, model=\"MobileNetV2\", height=160, width=160):\n",
    "        \"\"\"Creates an ImageFeatureExtractor using the specified model.\"\"\"\n",
    "        self.height, self.width = height, width\n",
    "        if model == \"MobileNetV2\":\n",
    "            base_model = tf.keras.applications.MobileNetV2(\n",
    "                input_shape=(height, width, 3),\n",
    "               include_top=False,\n",
    "               weights='imagenet'\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"Model unknown\")\n",
    "        global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.model = tf.keras.Sequential([base_model, global_average_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fit(self, X, y):\n",
    "        \"\"\"We're using a pre-trained model, so there's nothing to fit.\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def transform(self, X):\n",
    "        \"\"\"Transforms image file paths into Numpy arrays of deep features.\"\"\"\n",
    "        result = []\n",
    "        for image_pathname in X:\n",
    "            result.append(self._transform_one(image_pathname))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_one(image_pathname):\n",
    "    \"\"\"Transforms a single image pathname into deep features.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_pathname)\n",
    "    except:\n",
    "        response = requests.get(image_pathname)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "    img.load()\n",
    "    img = img.convert(\"RGB\")\n",
    "    image = np.asarray(img)\n",
    "    image = image[:,:,:3]\n",
    "    return image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_one(png[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test6 = np.asarray(png)\n",
    "test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _prepare_image(self, image):\n",
    "        \"\"\"Converts an image to the expected format for prediction.\"\"\"\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = (image/127.5) - 1\n",
    "        image = tf.image.resize(image, (self.height, self.width))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _extract_features(self, image):\n",
    "        \"\"\"Return a vector of 1280 deep features for image.\"\"\"\n",
    "        image_resized = self._prepare_image(image)\n",
    "        image_np = image_resized.numpy()\n",
    "        images_np = np.expand_dims(image_np, axis=0)\n",
    "        image_np.shape, images_np.shape\n",
    "        deep_features = self.model.predict(images_np)\n",
    "        return deep_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fetch_image_from_s3(self, bucket, key):            \n",
    "        \"\"\"Fetches an image from S3 and returns a numpy array.\"\"\"\n",
    "        s3 = boto3.client('s3')\n",
    "        response = s3.get_object(Bucket=bucket, Key=key)\n",
    "        body = response['Body']\n",
    "        data = body.read()    \n",
    "        f = BytesIO(data)\n",
    "        image = Image.open(f)   \n",
    "        image_data = np.asarray(image)\n",
    "        return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros( (106, 106, 3) )\n",
    "result = x[:, :, :2]\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP DELETING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Class\n",
    "extractor = ImageFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store Features - list of arrays\n",
    "features = extractor.transform(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into list of lists because easier with MongoDB\n",
    "features_list = [feature.tolist() for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip them so can iterate through them\n",
    "zipped_imgs = list(zip(image_paths,features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of dictionaries; so can be ingested by MongoDB\n",
    "list_of_dicts = [{'url': img[0], 'features':img[1]} for img in zipped_imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload results to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate client\n",
    "client = pymongo.MongoClient(\"mongodb+srv://\" + mongo_user + \":\" \n",
    "                         + mongo_pw \n",
    "                         + \"@dsaf-oy1s0.mongodb.net/test?retryWrites=true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DB, Collection\n",
    "db = client['furious']\n",
    "coll = db['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wipe collection to start fresh\n",
    "coll.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Results\n",
    "coll.insert_many(list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_returned = [np.array(x['features']) for x in coll.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSM Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    target, \n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(criterion = \"gini\", max_depth = 5) \n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree_clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is likely not right.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_returned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1518137569197-67c41a95d8de?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=2560&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### _We can do train / test split before we push through classification models?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = [(img.numpy(), label.numpy())\n",
    "                for (img, label) in raw_train.take(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [(img.numpy(), label.numpy())\n",
    "               for (img, label) in raw_test.take(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0][0])\n",
    "plt.title(get_label_name(train_images[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_img, train_y = zip(*train_images)\n",
    "test_X_img, test_y = zip(*test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LIMIT = 1000\n",
    "TEST_LIMIT = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_small = [extract_features(img)\n",
    "                 for img in train_X_img[:TRAIN_LIMIT]]\n",
    "test_X_small = [extract_features(img)\n",
    "                for img in test_X_img[:TEST_LIMIT]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_small = train_y[:TRAIN_LIMIT]\n",
    "test_y_small = test_y[:TEST_LIMIT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on Deep Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(train_X_small, train_y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = lr.predict(train_X_small)\n",
    "(sum(train_y_small) / len(train_y_small),\n",
    " sum(train_preds == train_y_small) / len(train_y_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = lr.predict(test_X_small)\n",
    "(sum(test_y_small) / len(test_y_small),\n",
    " sum(test_preds == test_y_small) / len(test_y_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=np.argsort(np.abs(lr.coef_[0]))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({'values': lr.coef_[0][idxs], 'idx': idxs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest on Deep Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "rfc.fit(train_X_small, train_y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = rfc.predict(train_X_small)\n",
    "(sum(train_y_small) / len(train_y_small),\n",
    " sum(train_preds == train_y_small) / len(train_y_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_X_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = rfc.predict(test_X_small)\n",
    "(sum(test_y_small) / len(test_y_small),\n",
    " sum(test_preds == test_y_small) / len(test_y_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_idxs = np.argsort(rfc.feature_importances_)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.feature_importances_[rf_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_test_df = test_df.copy()\n",
    "idx_list = rf_idxs[:10]\n",
    "for idx in idx_list:\n",
    "    important_feature = test_df.loc[:, idx].copy().values\n",
    "    np.random.shuffle(important_feature)\n",
    "    permuted_test_df.loc[:, idx] = important_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = rfc.predict(permuted_test_df)\n",
    "(sum(test_y_small) / len(test_y_small),\n",
    " sum(test_preds == test_y_small) / len(test_y_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look at DB names\n",
    "cur = client.list_databases()\n",
    "\n",
    "for item in cur:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Look at everything in our collection!\n",
    "cur = coll.find({})\n",
    "\n",
    "for item in cur:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
